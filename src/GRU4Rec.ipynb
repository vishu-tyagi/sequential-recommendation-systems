{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gru4rec.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install recbole"
      ],
      "metadata": {
        "id": "lgrtxqOZ35vN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pfOzpdBdOIKK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "os.chdir('/content/drive/MyDrive/hnm')\n",
        "DATA_PATH = Path.cwd() / 'data'\n",
        "RAW = DATA_PATH / 'raw'\n",
        "PROCESSED = DATA_PATH / 'processed'\n",
        "SUBMISSION = DATA_PATH / 'submission'\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import logging\n",
        "from logging import getLogger\n",
        "from recbole.config import Config\n",
        "from recbole.data import create_dataset, data_preparation\n",
        "from recbole.model.sequential_recommender import GRU4Rec\n",
        "from recbole.trainer import Trainer\n",
        "from recbole.utils import init_seed, init_logger"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/hnm/gru4rec')"
      ],
      "metadata": {
        "id": "KFn0LnVbn8uU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameter_dict = {\n",
        "    'data_path': PROCESSED,\n",
        "    'USER_ID_FIELD': 'user_id',\n",
        "    'ITEM_ID_FIELD': 'item_id',\n",
        "    'TIME_FIELD': 'timestamp',\n",
        "    'user_inter_num_interval': \"[40,inf)\",\n",
        "    'item_inter_num_interval': \"[40,inf)\",\n",
        "    'load_col': {'inter': ['user_id', 'item_id', 'timestamp']},\n",
        "    'neg_sampling': None,\n",
        "    'epochs': 50,\n",
        "    'metrics': ['MAP'],\n",
        "    'valid_metric': 'MAP@12',\n",
        "    'topk': [12],\n",
        "    'eval_args': {\n",
        "        'split': {'RS': [9, 0, 1]},\n",
        "        'group_by': 'user',\n",
        "        'order': 'TO',\n",
        "        'mode': 'full'}\n",
        "}\n",
        "\n",
        "config = Config(model='GRU4Rec', dataset='recbox_data', config_dict=parameter_dict)\n",
        "\n",
        "# init random seed\n",
        "init_seed(config['seed'], config['reproducibility'])\n",
        "\n",
        "# logger initialization\n",
        "init_logger(config)\n",
        "logger = getLogger()\n",
        "# Create handlers\n",
        "c_handler = logging.StreamHandler()\n",
        "c_handler.setLevel(logging.INFO)\n",
        "logger.addHandler(c_handler)\n",
        "\n",
        "# write config info into log\n",
        "logger.info(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlm4T8E-TCla",
        "outputId": "cc5ed6b2-ff48-4e28-f957-b71d0b4abb48"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "29 Mar 12:23    INFO  \n",
            "General Hyper Parameters:\n",
            "gpu_id = 0\n",
            "use_gpu = True\n",
            "seed = 2020\n",
            "state = INFO\n",
            "reproducibility = True\n",
            "data_path = /content/drive/MyDrive/hnm/data/processed/recbox_data\n",
            "checkpoint_dir = saved\n",
            "show_progress = True\n",
            "save_dataset = False\n",
            "dataset_save_path = None\n",
            "save_dataloaders = False\n",
            "dataloaders_save_path = None\n",
            "log_wandb = False\n",
            "\n",
            "Training Hyper Parameters:\n",
            "epochs = 50\n",
            "train_batch_size = 2048\n",
            "learner = adam\n",
            "learning_rate = 0.001\n",
            "neg_sampling = None\n",
            "eval_step = 1\n",
            "stopping_step = 10\n",
            "clip_grad_norm = None\n",
            "weight_decay = 0.0\n",
            "loss_decimal_place = 4\n",
            "\n",
            "Evaluation Hyper Parameters:\n",
            "eval_args = {'split': {'RS': [9, 0, 1]}, 'group_by': 'user', 'order': 'TO', 'mode': 'full'}\n",
            "repeatable = True\n",
            "metrics = ['MAP']\n",
            "topk = [12]\n",
            "valid_metric = MAP@12\n",
            "valid_metric_bigger = True\n",
            "eval_batch_size = 4096\n",
            "metric_decimal_place = 4\n",
            "\n",
            "Dataset Hyper Parameters:\n",
            "field_separator = \t\n",
            "seq_separator =  \n",
            "USER_ID_FIELD = user_id\n",
            "ITEM_ID_FIELD = item_id\n",
            "RATING_FIELD = rating\n",
            "TIME_FIELD = timestamp\n",
            "seq_len = None\n",
            "LABEL_FIELD = label\n",
            "threshold = None\n",
            "NEG_PREFIX = neg_\n",
            "load_col = {'inter': ['user_id', 'item_id', 'timestamp']}\n",
            "unload_col = None\n",
            "unused_col = None\n",
            "additional_feat_suffix = None\n",
            "rm_dup_inter = None\n",
            "val_interval = None\n",
            "filter_inter_by_user_or_item = True\n",
            "user_inter_num_interval = [40,inf)\n",
            "item_inter_num_interval = [40,inf)\n",
            "alias_of_user_id = None\n",
            "alias_of_item_id = None\n",
            "alias_of_entity_id = None\n",
            "alias_of_relation_id = None\n",
            "preload_weight = None\n",
            "normalize_field = None\n",
            "normalize_all = None\n",
            "ITEM_LIST_LENGTH_FIELD = item_length\n",
            "LIST_SUFFIX = _list\n",
            "MAX_ITEM_LIST_LENGTH = 50\n",
            "POSITION_FIELD = position_id\n",
            "HEAD_ENTITY_ID_FIELD = head_id\n",
            "TAIL_ENTITY_ID_FIELD = tail_id\n",
            "RELATION_ID_FIELD = relation_id\n",
            "ENTITY_ID_FIELD = entity_id\n",
            "benchmark_filename = None\n",
            "\n",
            "Other Hyper Parameters: \n",
            "wandb_project = recbole\n",
            "require_pow = False\n",
            "embedding_size = 64\n",
            "hidden_size = 128\n",
            "num_layers = 1\n",
            "dropout_prob = 0.3\n",
            "loss_type = CE\n",
            "MODEL_TYPE = ModelType.SEQUENTIAL\n",
            "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
            "eval_type = EvaluatorType.RANKING\n",
            "device = cuda\n",
            "train_neg_sample_args = {'strategy': 'none'}\n",
            "eval_neg_sample_args = {'strategy': 'full', 'distribution': 'uniform'}\n",
            "\n",
            "\n",
            "\n",
            "General Hyper Parameters:\n",
            "gpu_id = 0\n",
            "use_gpu = True\n",
            "seed = 2020\n",
            "state = INFO\n",
            "reproducibility = True\n",
            "data_path = /content/drive/MyDrive/hnm/data/processed/recbox_data\n",
            "checkpoint_dir = saved\n",
            "show_progress = True\n",
            "save_dataset = False\n",
            "dataset_save_path = None\n",
            "save_dataloaders = False\n",
            "dataloaders_save_path = None\n",
            "log_wandb = False\n",
            "\n",
            "Training Hyper Parameters:\n",
            "epochs = 50\n",
            "train_batch_size = 2048\n",
            "learner = adam\n",
            "learning_rate = 0.001\n",
            "neg_sampling = None\n",
            "eval_step = 1\n",
            "stopping_step = 10\n",
            "clip_grad_norm = None\n",
            "weight_decay = 0.0\n",
            "loss_decimal_place = 4\n",
            "\n",
            "Evaluation Hyper Parameters:\n",
            "eval_args = {'split': {'RS': [9, 0, 1]}, 'group_by': 'user', 'order': 'TO', 'mode': 'full'}\n",
            "repeatable = True\n",
            "metrics = ['MAP']\n",
            "topk = [12]\n",
            "valid_metric = MAP@12\n",
            "valid_metric_bigger = True\n",
            "eval_batch_size = 4096\n",
            "metric_decimal_place = 4\n",
            "\n",
            "Dataset Hyper Parameters:\n",
            "field_separator = \t\n",
            "seq_separator =  \n",
            "USER_ID_FIELD = user_id\n",
            "ITEM_ID_FIELD = item_id\n",
            "RATING_FIELD = rating\n",
            "TIME_FIELD = timestamp\n",
            "seq_len = None\n",
            "LABEL_FIELD = label\n",
            "threshold = None\n",
            "NEG_PREFIX = neg_\n",
            "load_col = {'inter': ['user_id', 'item_id', 'timestamp']}\n",
            "unload_col = None\n",
            "unused_col = None\n",
            "additional_feat_suffix = None\n",
            "rm_dup_inter = None\n",
            "val_interval = None\n",
            "filter_inter_by_user_or_item = True\n",
            "user_inter_num_interval = [40,inf)\n",
            "item_inter_num_interval = [40,inf)\n",
            "alias_of_user_id = None\n",
            "alias_of_item_id = None\n",
            "alias_of_entity_id = None\n",
            "alias_of_relation_id = None\n",
            "preload_weight = None\n",
            "normalize_field = None\n",
            "normalize_all = None\n",
            "ITEM_LIST_LENGTH_FIELD = item_length\n",
            "LIST_SUFFIX = _list\n",
            "MAX_ITEM_LIST_LENGTH = 50\n",
            "POSITION_FIELD = position_id\n",
            "HEAD_ENTITY_ID_FIELD = head_id\n",
            "TAIL_ENTITY_ID_FIELD = tail_id\n",
            "RELATION_ID_FIELD = relation_id\n",
            "ENTITY_ID_FIELD = entity_id\n",
            "benchmark_filename = None\n",
            "\n",
            "Other Hyper Parameters: \n",
            "wandb_project = recbole\n",
            "require_pow = False\n",
            "embedding_size = 64\n",
            "hidden_size = 128\n",
            "num_layers = 1\n",
            "dropout_prob = 0.3\n",
            "loss_type = CE\n",
            "MODEL_TYPE = ModelType.SEQUENTIAL\n",
            "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
            "eval_type = EvaluatorType.RANKING\n",
            "device = cuda\n",
            "train_neg_sample_args = {'strategy': 'none'}\n",
            "eval_neg_sample_args = {'strategy': 'full', 'distribution': 'uniform'}\n",
            "\n",
            "\n",
            "\n",
            "General Hyper Parameters:\n",
            "gpu_id = 0\n",
            "use_gpu = True\n",
            "seed = 2020\n",
            "state = INFO\n",
            "reproducibility = True\n",
            "data_path = /content/drive/MyDrive/hnm/data/processed/recbox_data\n",
            "checkpoint_dir = saved\n",
            "show_progress = True\n",
            "save_dataset = False\n",
            "dataset_save_path = None\n",
            "save_dataloaders = False\n",
            "dataloaders_save_path = None\n",
            "log_wandb = False\n",
            "\n",
            "Training Hyper Parameters:\n",
            "epochs = 50\n",
            "train_batch_size = 2048\n",
            "learner = adam\n",
            "learning_rate = 0.001\n",
            "neg_sampling = None\n",
            "eval_step = 1\n",
            "stopping_step = 10\n",
            "clip_grad_norm = None\n",
            "weight_decay = 0.0\n",
            "loss_decimal_place = 4\n",
            "\n",
            "Evaluation Hyper Parameters:\n",
            "eval_args = {'split': {'RS': [9, 0, 1]}, 'group_by': 'user', 'order': 'TO', 'mode': 'full'}\n",
            "repeatable = True\n",
            "metrics = ['MAP']\n",
            "topk = [12]\n",
            "valid_metric = MAP@12\n",
            "valid_metric_bigger = True\n",
            "eval_batch_size = 4096\n",
            "metric_decimal_place = 4\n",
            "\n",
            "Dataset Hyper Parameters:\n",
            "field_separator = \t\n",
            "seq_separator =  \n",
            "USER_ID_FIELD = user_id\n",
            "ITEM_ID_FIELD = item_id\n",
            "RATING_FIELD = rating\n",
            "TIME_FIELD = timestamp\n",
            "seq_len = None\n",
            "LABEL_FIELD = label\n",
            "threshold = None\n",
            "NEG_PREFIX = neg_\n",
            "load_col = {'inter': ['user_id', 'item_id', 'timestamp']}\n",
            "unload_col = None\n",
            "unused_col = None\n",
            "additional_feat_suffix = None\n",
            "rm_dup_inter = None\n",
            "val_interval = None\n",
            "filter_inter_by_user_or_item = True\n",
            "user_inter_num_interval = [40,inf)\n",
            "item_inter_num_interval = [40,inf)\n",
            "alias_of_user_id = None\n",
            "alias_of_item_id = None\n",
            "alias_of_entity_id = None\n",
            "alias_of_relation_id = None\n",
            "preload_weight = None\n",
            "normalize_field = None\n",
            "normalize_all = None\n",
            "ITEM_LIST_LENGTH_FIELD = item_length\n",
            "LIST_SUFFIX = _list\n",
            "MAX_ITEM_LIST_LENGTH = 50\n",
            "POSITION_FIELD = position_id\n",
            "HEAD_ENTITY_ID_FIELD = head_id\n",
            "TAIL_ENTITY_ID_FIELD = tail_id\n",
            "RELATION_ID_FIELD = relation_id\n",
            "ENTITY_ID_FIELD = entity_id\n",
            "benchmark_filename = None\n",
            "\n",
            "Other Hyper Parameters: \n",
            "wandb_project = recbole\n",
            "require_pow = False\n",
            "embedding_size = 64\n",
            "hidden_size = 128\n",
            "num_layers = 1\n",
            "dropout_prob = 0.3\n",
            "loss_type = CE\n",
            "MODEL_TYPE = ModelType.SEQUENTIAL\n",
            "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
            "eval_type = EvaluatorType.RANKING\n",
            "device = cuda\n",
            "train_neg_sample_args = {'strategy': 'none'}\n",
            "eval_neg_sample_args = {'strategy': 'full', 'distribution': 'uniform'}\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = create_dataset(config)\n",
        "logger.info(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSuDOJ7bTXK3",
        "outputId": "f8febeb2-f4ae-4694-9130-cd2c3c8754b0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "29 Mar 12:28    INFO  recbox_data\n",
            "The number of users: 223128\n",
            "Average actions of users: 85.38935673405729\n",
            "The number of items: 51558\n",
            "Average actions of items: 369.5457648815874\n",
            "The number of inters: 19052671\n",
            "The sparsity of the dataset: 99.8343826873777%\n",
            "Remain Fields: ['user_id', 'item_id', 'timestamp']\n",
            "recbox_data\n",
            "The number of users: 223128\n",
            "Average actions of users: 85.38935673405729\n",
            "The number of items: 51558\n",
            "Average actions of items: 369.5457648815874\n",
            "The number of inters: 19052671\n",
            "The sparsity of the dataset: 99.8343826873777%\n",
            "Remain Fields: ['user_id', 'item_id', 'timestamp']\n",
            "recbox_data\n",
            "The number of users: 223128\n",
            "Average actions of users: 85.38935673405729\n",
            "The number of items: 51558\n",
            "Average actions of items: 369.5457648815874\n",
            "The number of inters: 19052671\n",
            "The sparsity of the dataset: 99.8343826873777%\n",
            "Remain Fields: ['user_id', 'item_id', 'timestamp']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, valid_data, test_data = data_preparation(config, dataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVvz_7EYTXdi",
        "outputId": "c8e7a3f7-2b97-495e-d9a6-f7ee17853ffa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "29 Mar 12:33    INFO  [Training]: train_batch_size = [2048] negative sampling: [None]\n",
            "[Training]: train_batch_size = [2048] negative sampling: [None]\n",
            "[Training]: train_batch_size = [2048] negative sampling: [None]\n",
            "29 Mar 12:33    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [9, 0, 1]}, 'group_by': 'user', 'order': 'TO', 'mode': 'full'}]\n",
            "[Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [9, 0, 1]}, 'group_by': 'user', 'order': 'TO', 'mode': 'full'}]\n",
            "[Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [9, 0, 1]}, 'group_by': 'user', 'order': 'TO', 'mode': 'full'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = GRU4Rec(config, train_data.dataset).to(config['device'])\n",
        "logger.info(model)"
      ],
      "metadata": {
        "id": "eC07_j-mPmF8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5246b0e4-205d-4ddc-a650-9b35446375e2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "29 Mar 12:34    INFO  GRU4Rec(\n",
            "  (item_embedding): Embedding(51558, 64, padding_idx=0)\n",
            "  (emb_dropout): Dropout(p=0.3, inplace=False)\n",
            "  (gru_layers): GRU(64, 128, bias=False, batch_first=True)\n",
            "  (dense): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (loss_fct): CrossEntropyLoss()\n",
            ")\n",
            "Trainable parameters: 3381696\n",
            "GRU4Rec(\n",
            "  (item_embedding): Embedding(51558, 64, padding_idx=0)\n",
            "  (emb_dropout): Dropout(p=0.3, inplace=False)\n",
            "  (gru_layers): GRU(64, 128, bias=False, batch_first=True)\n",
            "  (dense): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (loss_fct): CrossEntropyLoss()\n",
            ")\n",
            "Trainable parameters: 3381696\n",
            "GRU4Rec(\n",
            "  (item_embedding): Embedding(51558, 64, padding_idx=0)\n",
            "  (emb_dropout): Dropout(p=0.3, inplace=False)\n",
            "  (gru_layers): GRU(64, 128, bias=False, batch_first=True)\n",
            "  (dense): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (loss_fct): CrossEntropyLoss()\n",
            ")\n",
            "Trainable parameters: 3381696\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(config, model)"
      ],
      "metadata": {
        "id": "hgPIvcfqq7Sr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_valid_score, best_valid_result = trainer.fit(train_data, valid_data=valid_data, show_progress=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exVIgfDtCxMW",
        "outputId": "76971e7b-418d-4b7d-e42d-b2f61eb6cf5f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train     0: 100%|█████████████████████| 8323/8323 [05:39<00:00, 24.53it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 12:40    INFO  epoch 0 training [time: 339.31s, train loss: 71936.9081]\n",
            "epoch 0 training [time: 339.31s, train loss: 71936.9081]\n",
            "epoch 0 training [time: 339.31s, train loss: 71936.9081]\n",
            "29 Mar 12:40    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train     1: 100%|█████████████████████| 8323/8323 [05:37<00:00, 24.68it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 12:46    INFO  epoch 1 training [time: 337.19s, train loss: 66461.1367]\n",
            "epoch 1 training [time: 337.19s, train loss: 66461.1367]\n",
            "epoch 1 training [time: 337.19s, train loss: 66461.1367]\n",
            "29 Mar 12:46    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train     2: 100%|█████████████████████| 8323/8323 [05:36<00:00, 24.70it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 12:52    INFO  epoch 2 training [time: 336.94s, train loss: 64798.1579]\n",
            "epoch 2 training [time: 336.94s, train loss: 64798.1579]\n",
            "epoch 2 training [time: 336.94s, train loss: 64798.1579]\n",
            "29 Mar 12:52    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train     3: 100%|█████████████████████| 8323/8323 [05:35<00:00, 24.84it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 12:57    INFO  epoch 3 training [time: 335.14s, train loss: 63887.0065]\n",
            "epoch 3 training [time: 335.14s, train loss: 63887.0065]\n",
            "epoch 3 training [time: 335.14s, train loss: 63887.0065]\n",
            "29 Mar 12:57    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train     4: 100%|█████████████████████| 8323/8323 [05:36<00:00, 24.71it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 13:03    INFO  epoch 4 training [time: 336.79s, train loss: 63305.2948]\n",
            "epoch 4 training [time: 336.79s, train loss: 63305.2948]\n",
            "epoch 4 training [time: 336.79s, train loss: 63305.2948]\n",
            "29 Mar 13:03    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train     5: 100%|█████████████████████| 8323/8323 [05:34<00:00, 24.88it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 13:08    INFO  epoch 5 training [time: 334.53s, train loss: 62920.9997]\n",
            "epoch 5 training [time: 334.53s, train loss: 62920.9997]\n",
            "epoch 5 training [time: 334.53s, train loss: 62920.9997]\n",
            "29 Mar 13:08    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train     6: 100%|█████████████████████| 8323/8323 [05:34<00:00, 24.85it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 13:14    INFO  epoch 6 training [time: 334.97s, train loss: 62650.8588]\n",
            "epoch 6 training [time: 334.97s, train loss: 62650.8588]\n",
            "epoch 6 training [time: 334.97s, train loss: 62650.8588]\n",
            "29 Mar 13:14    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train     7: 100%|█████████████████████| 8323/8323 [05:30<00:00, 25.22it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 13:20    INFO  epoch 7 training [time: 330.03s, train loss: 62453.8889]\n",
            "epoch 7 training [time: 330.03s, train loss: 62453.8889]\n",
            "epoch 7 training [time: 330.03s, train loss: 62453.8889]\n",
            "29 Mar 13:20    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train     8: 100%|█████████████████████| 8323/8323 [05:32<00:00, 25.03it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 13:25    INFO  epoch 8 training [time: 332.57s, train loss: 62299.6933]\n",
            "epoch 8 training [time: 332.57s, train loss: 62299.6933]\n",
            "epoch 8 training [time: 332.57s, train loss: 62299.6933]\n",
            "29 Mar 13:25    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train     9: 100%|█████████████████████| 8323/8323 [05:37<00:00, 24.62it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 13:31    INFO  epoch 9 training [time: 338.01s, train loss: 62172.5099]\n",
            "epoch 9 training [time: 338.01s, train loss: 62172.5099]\n",
            "epoch 9 training [time: 338.01s, train loss: 62172.5099]\n",
            "29 Mar 13:31    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train    10: 100%|█████████████████████| 8323/8323 [05:39<00:00, 24.48it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 13:36    INFO  epoch 10 training [time: 339.96s, train loss: 62069.5242]\n",
            "epoch 10 training [time: 339.96s, train loss: 62069.5242]\n",
            "epoch 10 training [time: 339.96s, train loss: 62069.5242]\n",
            "29 Mar 13:36    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train    11: 100%|█████████████████████| 8323/8323 [05:39<00:00, 24.54it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 13:42    INFO  epoch 11 training [time: 339.11s, train loss: 61979.8297]\n",
            "epoch 11 training [time: 339.11s, train loss: 61979.8297]\n",
            "epoch 11 training [time: 339.11s, train loss: 61979.8297]\n",
            "29 Mar 13:42    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train    12: 100%|█████████████████████| 8323/8323 [05:42<00:00, 24.33it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 13:48    INFO  epoch 12 training [time: 342.05s, train loss: 61904.8058]\n",
            "epoch 12 training [time: 342.05s, train loss: 61904.8058]\n",
            "epoch 12 training [time: 342.05s, train loss: 61904.8058]\n",
            "29 Mar 13:48    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train    13: 100%|█████████████████████| 8323/8323 [05:45<00:00, 24.07it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 13:53    INFO  epoch 13 training [time: 345.85s, train loss: 61841.2200]\n",
            "epoch 13 training [time: 345.85s, train loss: 61841.2200]\n",
            "epoch 13 training [time: 345.85s, train loss: 61841.2200]\n",
            "29 Mar 13:53    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train    14: 100%|█████████████████████| 8323/8323 [05:42<00:00, 24.27it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 13:59    INFO  epoch 14 training [time: 342.91s, train loss: 61784.5272]\n",
            "epoch 14 training [time: 342.91s, train loss: 61784.5272]\n",
            "epoch 14 training [time: 342.91s, train loss: 61784.5272]\n",
            "29 Mar 13:59    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train    15: 100%|█████████████████████| 8323/8323 [05:42<00:00, 24.28it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 14:05    INFO  epoch 15 training [time: 342.81s, train loss: 61734.6203]\n",
            "epoch 15 training [time: 342.81s, train loss: 61734.6203]\n",
            "epoch 15 training [time: 342.81s, train loss: 61734.6203]\n",
            "29 Mar 14:05    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train    16: 100%|█████████████████████| 8323/8323 [05:43<00:00, 24.24it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 14:11    INFO  epoch 16 training [time: 343.35s, train loss: 61690.5179]\n",
            "epoch 16 training [time: 343.35s, train loss: 61690.5179]\n",
            "epoch 16 training [time: 343.35s, train loss: 61690.5179]\n",
            "29 Mar 14:11    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train    17: 100%|█████████████████████| 8323/8323 [05:42<00:00, 24.27it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 14:16    INFO  epoch 17 training [time: 342.99s, train loss: 61650.3699]\n",
            "epoch 17 training [time: 342.99s, train loss: 61650.3699]\n",
            "epoch 17 training [time: 342.99s, train loss: 61650.3699]\n",
            "29 Mar 14:16    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train    18: 100%|█████████████████████| 8323/8323 [05:44<00:00, 24.17it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 14:22    INFO  epoch 18 training [time: 344.39s, train loss: 61617.3958]\n",
            "epoch 18 training [time: 344.39s, train loss: 61617.3958]\n",
            "epoch 18 training [time: 344.39s, train loss: 61617.3958]\n",
            "29 Mar 14:22    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train    19: 100%|█████████████████████| 8323/8323 [05:43<00:00, 24.25it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 14:28    INFO  epoch 19 training [time: 343.26s, train loss: 61587.4211]\n",
            "epoch 19 training [time: 343.26s, train loss: 61587.4211]\n",
            "epoch 19 training [time: 343.26s, train loss: 61587.4211]\n",
            "29 Mar 14:28    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train    20: 100%|█████████████████████| 8323/8323 [05:45<00:00, 24.09it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 14:34    INFO  epoch 20 training [time: 345.58s, train loss: 61557.8949]\n",
            "epoch 20 training [time: 345.58s, train loss: 61557.8949]\n",
            "epoch 20 training [time: 345.58s, train loss: 61557.8949]\n",
            "29 Mar 14:34    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train    21: 100%|█████████████████████| 8323/8323 [05:44<00:00, 24.14it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 14:39    INFO  epoch 21 training [time: 344.76s, train loss: 61534.3443]\n",
            "epoch 21 training [time: 344.76s, train loss: 61534.3443]\n",
            "epoch 21 training [time: 344.76s, train loss: 61534.3443]\n",
            "29 Mar 14:39    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train    22: 100%|█████████████████████| 8323/8323 [05:44<00:00, 24.18it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 14:45    INFO  epoch 22 training [time: 344.19s, train loss: 61510.4295]\n",
            "epoch 22 training [time: 344.19s, train loss: 61510.4295]\n",
            "epoch 22 training [time: 344.19s, train loss: 61510.4295]\n",
            "29 Mar 14:45    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train    23: 100%|█████████████████████| 8323/8323 [05:45<00:00, 24.09it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 14:51    INFO  epoch 23 training [time: 345.58s, train loss: 61491.4501]\n",
            "epoch 23 training [time: 345.58s, train loss: 61491.4501]\n",
            "epoch 23 training [time: 345.58s, train loss: 61491.4501]\n",
            "29 Mar 14:51    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train    24: 100%|█████████████████████| 8323/8323 [05:45<00:00, 24.09it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 14:57    INFO  epoch 24 training [time: 345.51s, train loss: 61472.6081]\n",
            "epoch 24 training [time: 345.51s, train loss: 61472.6081]\n",
            "epoch 24 training [time: 345.51s, train loss: 61472.6081]\n",
            "29 Mar 14:57    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train    25: 100%|█████████████████████| 8323/8323 [05:42<00:00, 24.33it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 15:02    INFO  epoch 25 training [time: 342.11s, train loss: 61453.2877]\n",
            "epoch 25 training [time: 342.11s, train loss: 61453.2877]\n",
            "epoch 25 training [time: 342.11s, train loss: 61453.2877]\n",
            "29 Mar 15:02    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train    26: 100%|█████████████████████| 8323/8323 [05:37<00:00, 24.66it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 15:08    INFO  epoch 26 training [time: 337.47s, train loss: 61438.8641]\n",
            "epoch 26 training [time: 337.47s, train loss: 61438.8641]\n",
            "epoch 26 training [time: 337.47s, train loss: 61438.8641]\n",
            "29 Mar 15:08    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train    27: 100%|█████████████████████| 8323/8323 [05:37<00:00, 24.63it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 15:14    INFO  epoch 27 training [time: 337.95s, train loss: 61423.0576]\n",
            "epoch 27 training [time: 337.95s, train loss: 61423.0576]\n",
            "epoch 27 training [time: 337.95s, train loss: 61423.0576]\n",
            "29 Mar 15:14    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train    28: 100%|█████████████████████| 8323/8323 [05:37<00:00, 24.64it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 15:19    INFO  epoch 28 training [time: 337.75s, train loss: 61409.7891]\n",
            "epoch 28 training [time: 337.75s, train loss: 61409.7891]\n",
            "epoch 28 training [time: 337.75s, train loss: 61409.7891]\n",
            "29 Mar 15:19    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train    29: 100%|█████████████████████| 8323/8323 [05:39<00:00, 24.53it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 15:25    INFO  epoch 29 training [time: 339.28s, train loss: 61397.5963]\n",
            "epoch 29 training [time: 339.28s, train loss: 61397.5963]\n",
            "epoch 29 training [time: 339.28s, train loss: 61397.5963]\n",
            "29 Mar 15:25    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train    30: 100%|█████████████████████| 8323/8323 [05:38<00:00, 24.61it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 15:31    INFO  epoch 30 training [time: 338.15s, train loss: 61384.7397]\n",
            "epoch 30 training [time: 338.15s, train loss: 61384.7397]\n",
            "epoch 30 training [time: 338.15s, train loss: 61384.7397]\n",
            "29 Mar 15:31    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train    31: 100%|█████████████████████| 8323/8323 [05:38<00:00, 24.58it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 15:36    INFO  epoch 31 training [time: 338.61s, train loss: 61370.4994]\n",
            "epoch 31 training [time: 338.61s, train loss: 61370.4994]\n",
            "epoch 31 training [time: 338.61s, train loss: 61370.4994]\n",
            "29 Mar 15:36    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train    32: 100%|█████████████████████| 8323/8323 [05:41<00:00, 24.35it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 15:42    INFO  epoch 32 training [time: 341.80s, train loss: 61362.1523]\n",
            "epoch 32 training [time: 341.80s, train loss: 61362.1523]\n",
            "epoch 32 training [time: 341.80s, train loss: 61362.1523]\n",
            "29 Mar 15:42    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train    33: 100%|█████████████████████| 8323/8323 [05:41<00:00, 24.36it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 15:48    INFO  epoch 33 training [time: 341.64s, train loss: 61351.4307]\n",
            "epoch 33 training [time: 341.64s, train loss: 61351.4307]\n",
            "epoch 33 training [time: 341.64s, train loss: 61351.4307]\n",
            "29 Mar 15:48    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train    34: 100%|█████████████████████| 8323/8323 [05:41<00:00, 24.36it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 15:53    INFO  epoch 34 training [time: 341.69s, train loss: 61342.7241]\n",
            "epoch 34 training [time: 341.69s, train loss: 61342.7241]\n",
            "epoch 34 training [time: 341.69s, train loss: 61342.7241]\n",
            "29 Mar 15:53    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train    35: 100%|█████████████████████| 8323/8323 [05:38<00:00, 24.57it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 15:59    INFO  epoch 35 training [time: 338.76s, train loss: 61332.7208]\n",
            "epoch 35 training [time: 338.76s, train loss: 61332.7208]\n",
            "epoch 35 training [time: 338.76s, train loss: 61332.7208]\n",
            "29 Mar 15:59    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train    36: 100%|█████████████████████| 8323/8323 [05:43<00:00, 24.26it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 16:05    INFO  epoch 36 training [time: 343.04s, train loss: 61323.8006]\n",
            "epoch 36 training [time: 343.04s, train loss: 61323.8006]\n",
            "epoch 36 training [time: 343.04s, train loss: 61323.8006]\n",
            "29 Mar 16:05    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train    37: 100%|█████████████████████| 8323/8323 [05:45<00:00, 24.06it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 16:10    INFO  epoch 37 training [time: 345.89s, train loss: 61318.2089]\n",
            "epoch 37 training [time: 345.89s, train loss: 61318.2089]\n",
            "epoch 37 training [time: 345.89s, train loss: 61318.2089]\n",
            "29 Mar 16:10    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train    38: 100%|█████████████████████| 8323/8323 [05:43<00:00, 24.20it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 16:16    INFO  epoch 38 training [time: 343.90s, train loss: 61311.0800]\n",
            "epoch 38 training [time: 343.90s, train loss: 61311.0800]\n",
            "epoch 38 training [time: 343.90s, train loss: 61311.0800]\n",
            "29 Mar 16:16    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train    39: 100%|█████████████████████| 8323/8323 [05:43<00:00, 24.23it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 16:22    INFO  epoch 39 training [time: 343.51s, train loss: 61302.7770]\n",
            "epoch 39 training [time: 343.51s, train loss: 61302.7770]\n",
            "epoch 39 training [time: 343.51s, train loss: 61302.7770]\n",
            "29 Mar 16:22    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train    40: 100%|█████████████████████| 8323/8323 [05:42<00:00, 24.29it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 16:28    INFO  epoch 40 training [time: 342.74s, train loss: 61296.4852]\n",
            "epoch 40 training [time: 342.74s, train loss: 61296.4852]\n",
            "epoch 40 training [time: 342.74s, train loss: 61296.4852]\n",
            "29 Mar 16:28    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train    41: 100%|█████████████████████| 8323/8323 [05:42<00:00, 24.28it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 16:33    INFO  epoch 41 training [time: 342.85s, train loss: 61289.8809]\n",
            "epoch 41 training [time: 342.85s, train loss: 61289.8809]\n",
            "epoch 41 training [time: 342.85s, train loss: 61289.8809]\n",
            "29 Mar 16:33    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train    42: 100%|█████████████████████| 8323/8323 [05:42<00:00, 24.29it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 16:39    INFO  epoch 42 training [time: 342.72s, train loss: 61282.8804]\n",
            "epoch 42 training [time: 342.72s, train loss: 61282.8804]\n",
            "epoch 42 training [time: 342.72s, train loss: 61282.8804]\n",
            "29 Mar 16:39    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train    43: 100%|█████████████████████| 8323/8323 [05:42<00:00, 24.31it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 16:45    INFO  epoch 43 training [time: 342.36s, train loss: 61278.2187]\n",
            "epoch 43 training [time: 342.36s, train loss: 61278.2187]\n",
            "epoch 43 training [time: 342.36s, train loss: 61278.2187]\n",
            "29 Mar 16:45    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train    44: 100%|█████████████████████| 8323/8323 [05:41<00:00, 24.34it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 16:50    INFO  epoch 44 training [time: 341.91s, train loss: 61271.4320]\n",
            "epoch 44 training [time: 341.91s, train loss: 61271.4320]\n",
            "epoch 44 training [time: 341.91s, train loss: 61271.4320]\n",
            "29 Mar 16:50    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train    45: 100%|█████████████████████| 8323/8323 [05:42<00:00, 24.27it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 16:56    INFO  epoch 45 training [time: 342.93s, train loss: 61267.7216]\n",
            "epoch 45 training [time: 342.93s, train loss: 61267.7216]\n",
            "epoch 45 training [time: 342.93s, train loss: 61267.7216]\n",
            "29 Mar 16:56    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train    46: 100%|█████████████████████| 8323/8323 [05:42<00:00, 24.30it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 17:02    INFO  epoch 46 training [time: 342.56s, train loss: 61262.3848]\n",
            "epoch 46 training [time: 342.56s, train loss: 61262.3848]\n",
            "epoch 46 training [time: 342.56s, train loss: 61262.3848]\n",
            "29 Mar 17:02    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train    47: 100%|█████████████████████| 8323/8323 [05:42<00:00, 24.30it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 17:08    INFO  epoch 47 training [time: 342.58s, train loss: 61258.2511]\n",
            "epoch 47 training [time: 342.58s, train loss: 61258.2511]\n",
            "epoch 47 training [time: 342.58s, train loss: 61258.2511]\n",
            "29 Mar 17:08    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train    48: 100%|█████████████████████| 8323/8323 [05:40<00:00, 24.42it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 17:13    INFO  epoch 48 training [time: 340.82s, train loss: 61252.0007]\n",
            "epoch 48 training [time: 340.82s, train loss: 61252.0007]\n",
            "epoch 48 training [time: 340.82s, train loss: 61252.0007]\n",
            "29 Mar 17:13    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Train    49: 100%|█████████████████████| 8323/8323 [05:43<00:00, 24.21it/s, GPU RAM: 2.20 G/15.78 G]\n",
            "29 Mar 17:19    INFO  epoch 49 training [time: 343.75s, train loss: 61248.0692]\n",
            "epoch 49 training [time: 343.75s, train loss: 61248.0692]\n",
            "epoch 49 training [time: 343.75s, train loss: 61248.0692]\n",
            "29 Mar 17:19    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
            "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sXOGR2_Ua7it"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}